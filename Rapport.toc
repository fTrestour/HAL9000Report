\select@language {french}
\contentsline {part}{I\hspace {1em}Introduction}{3}
\contentsline {section}{\numberline {0.1}Contexte}{4}
\contentsline {section}{\numberline {0.2}Pr\IeC {\'e}sentation du sujet}{4}
\contentsline {section}{\numberline {0.3}D\IeC {\'e}roulement}{4}
\contentsline {part}{II\hspace {1em}Le Perceptron}{5}
\contentsline {chapter}{\numberline {1}Architecture d'un perceptron}{6}
\contentsline {section}{\numberline {1.1}Introduction}{6}
\contentsline {section}{\numberline {1.2}La brique de base : le neurone}{6}
\contentsline {section}{\numberline {1.3}Organisation des couches}{8}
\contentsline {chapter}{\numberline {2}Algorithmes d'apprentissage}{11}
\contentsline {section}{\numberline {2.1}L'objectif des algorithmes d'apprentissage}{11}
\contentsline {section}{\numberline {2.2}La m\IeC {\'e}thode de r\IeC {\'e}tropropagation du gradient}{12}
\contentsline {chapter}{\numberline {3}Influence des param\IeC {\`e}tres sur l'apprentissage.}{13}
\contentsline {part}{III\hspace {1em}Machines de Boltzmann}{14}
\contentsline {chapter}{\numberline {4}Introduction}{15}
\contentsline {chapter}{\numberline {5}Les machines de Boltzmann restreintes}{16}
\contentsline {section}{\numberline {5.1}Principe}{16}
\contentsline {chapter}{\numberline {6}Les Deep Belief Networks}{17}
\contentsline {chapter}{\numberline {7}Aller plus loin}{18}
\contentsline {section}{\numberline {7.1}La visualisation des spectres du r\IeC {\'e}seau}{18}
\contentsline {chapter}{\numberline {A}La base MNIST.}{20}
\contentsline {chapter}{\numberline {B}Pr\IeC {\'e}sentation du code.}{21}
